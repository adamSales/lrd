---
title: "Limitless Regression Discontinuity"
author: "Adam Sales & Ben Hansen*"
date: "U. Wisconsin Statistics Dept (Nov. '19)"
bibliography: ../jebs/lrd-r1.bib
output: 
  ioslides_presentation:
     widescreen: false
  pdf_document:
     keep_tex: true
     toc: true
     toc_depth: 1
---
<!-- nocite:
  @hansenSales2015cochran-->
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

## Overview of talk

- Three perspectives on the regression discontinuity design (RDD)
- Specification testing: Methods to help pick out the RCT within a RDD
- Managing RDDs' inevitable imperfections
    + The "donut design"
    + Robustness to contamination of the sample
- $\Rightarrow$ unusual (to RDD literature) methods. Are the answers any different?


```{r child="1_threePerspectives+methodsForPickingOutRDDs.Rmd"}
```

```{r child="2_workingAroundDonut_formalRI.Rmd"}
```

```{r child="3_methodsForLimitingContamSens.Rmd"}
```

```{r child="4_areAnswersAnyDifferent.Rmd"}
```


## Discussion {.smaller}
<!-- Some of these points were added for ICORS audience. 
     For other audiences, cut/adjust as appropriate. -->

- In limit-based literature, main concern is with possibility that bandwidth/$\mathcal{W}$ is too wide.  (What about $\mathcal{W}$s that are too narrow, magnifying impact of contaminants?) To be "robust" to overly wide $\mathcal{W}$, prominent limit-based methods use local polynomials --- along w/ unbounded $\rho(\cdot)$, non-robust $s(\cdot)$.
- In the local randomization camp, recent methods narrow $\mathcal{W}$ until $H: X \perp Z| R\in \mathcal{W}$ is not rejected. Typically there is no allowance for $Y$--$R$ association other than via $Z=\mathcal{I}[R<0]$.  (What about $X$s that are plainly tied up with $R$?)
- Both camps wind up reducing $n$, if for different reasons.  Contamination becomes harder to detect, and more difficult to compensate for.
- Our "Limitless" method avoids these traps. 
- Furthermore, due to its use of robust M-estimation, it avoids
OLS's notorious instability with higher-order polynomials [@gelman2016high]. 
<!--
- Does a narrow enough "bandwidth" such as our $R\in [-.5, .5]$ entail that MM estimates are also bounded influence GM estimates?  If so, then $\mathrm{MaxBias}_\epsilon = O(\epsilon)$, not $O(\sqrt{\epsilon})$, as $\epsilon \downarrow 0$ [@he1991localbreakdown] --- a more satisfying complement to sample purification via specification tests.
-->


## Appendix: robustness weights {.build}

- Robust regression fitting generates "robustness" weights $\in [0,1]$, showing which observations the fitter deemed to be anomalous.
- If $\mathcal{W}$ is still too wide, or its donut hole isn't wide enough, plot of robustness weights against $R$ gives an additional shot at detection.  
- ![](./images/robwts.jpeg)

<!--  (To assign 0's to truly anomalous observations, not just any robust method will do; you need bounded influence regression.)-->


## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>




