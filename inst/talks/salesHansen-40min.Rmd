---
title: "Limitless Regression Discontinuity"
author: "Adam Sales & Ben Hansen*"
date: "Biostatistics Seminar, Ohio State (Mar. '19)"
bibliography: ../r1/causalinference.bib
output: 
  ioslides_presentation:
     widescreen: false
  pdf_document:
     keep_tex: true
     toc: true
     toc_depth: 1
---
<!-- nocite:
  @hansenSales2015cochran-->
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

## Overview of talk

- Three perspectives on the regression discontinuity design (RDD)
- Methods for picking out RCTs within RDDs
- Managing RDDs' inevitable imperfections
    + The "donut design"
    + Robustness to contamination of the sample
- $\Rightarrow$ unusual (to RDD literature) methods. Are the answers any different?


```{r child="1_threePerspectives+methodsForPickingOutRDDs.Rmd"}
```

```{r child="2_workingAroundDonut_formalRI.Rmd"}
```

```{r child="3_methodsForLimitingContamSens.Rmd"}
```

```{r child="4_areAnswersAnyDifferent.Rmd"}
```


## Discussion {.smaller}
<!-- Some of these points were added for ICORS audience. 
     For other audiences, cut/adjust as appropriate. -->

- In limit-based literature, main concern is with possibility that bandwidth/$\mathcal{W}$ is too wide.  To be "robust" to overly wide $\mathcal{W}$, prominent limit-based methods use local polynomials --- along w/ unbounded $\rho(\cdot)$, non-robust $s(\cdot)$.
- In the local randomization camp, recent methods narrow the window until covariates appear to be balanced. Typically there is no allowance for $Y$--$R$ association other than via $Z=\mathcal{I}[R<0]$. 
- Limit-based and local randomizers both led to reduce $n$.  This makes contamination harder to detect, and limits even robust M-estimates' capacity to compensate.
- Under moderate departure from linearity, robust M-estimation markedly improves power & type 1 error rates; see Sec. 5 of manuscript (`arxiv.org/abs/1403.5478`)
<!--
- Does a narrow enough "bandwidth" such as our $R\in [-.5, .5]$ entail that MM estimates are also bounded influence GM estimates?  If so, then $\mathrm{MaxBias}_\epsilon = O(\epsilon)$, not $O(\sqrt{\epsilon})$, as $\epsilon \downarrow 0$ [@he1991localbreakdown] --- a more satisfying complement to sample purification via specification tests.
-->

## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>




