\documentclass[12pt]{article}
\usepackage{setspace}

\usepackage{fullpage}
\usepackage{wrapfig}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts,amsthm,amsbsy}
\usepackage{stmaryrd} %bbm,
\usepackage{verbatim}
\usepackage[authoryear]{natbib}
\usepackage{soul}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{bm}
\usepackage{hyperref}
\hypersetup{colorlinks=true,
    linkcolor=blue,
    filecolor=blue,
    citecolor=black,
    urlcolor=cyan}
\usepackage{xr}


\newcommand{\maria}{Maria}
\newcommand{\TildeTheta}{\hat{\theta}}
\newcommand{\InfPar}[1]{\ensuremath{{#1}_{\infty}}}
\newcommand{\thetaInf}{\InfPar{\theta}}
\newcommand{\IC}[3][\hat\theta]{\mathrm{IF}_{#1}(#2, #3)}
\newcommand{\bty}{\mathbf{y}_H}
\newcommand{\btY}{\mathbf{Y}_H}
\newcommand{\tyi}{{y}_{Hi}}
\newcommand{\tYi}{{Y}_{Hi}}
\newcommand{\xch}{\check{X}}
\newcommand{\g}{g}
\newcommand{\ych}{e}
\newcommand{\Ych}{\ensuremath{E}}
\newcommand{\dt}[3][\theta]{\ensuremath{e_{#1}(#2| {#3})}}
\newcommand{\indicator}[1]{\ensuremath{\mathcal{I}\left[#1 \right]}}
                                %alternatives:
                                % {\ensuremath{\llbracket #1 \rrbracket}} % or \mathbbm{1}_{\left\{ {#1} \right\} }
                                % or maybe \chi_ instead of 1_
%\newcommand\independent{\protect\mathpalette{\protect\independenT}{\independent}}
\newcommand{\independent}{\perp}
\newcommand\hsg{\texttt{hsgrade\_pct}}
\newcommand{\hyp}{H_{\tau_0}}
\newcommand{\ychphib}{\boldsymbol{\check{Y}_{\phi_0}}}
\newcommand{\ychphi}{\check{Y}_{\boldsymbol{\phi_0}i}}
\newcommand{\PP}{\mathrm{Pr}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}
\newcommand{\htO}{H_{\tau_0}}
\newcommand{\tht}{\tilde{H}_{\tau_0}}
\newcommand{\resid}{E}
\newcommand{\meanDiffT}{T_{\tau}}



\externaldocument{lrd-r1}
\externaldocument{lrd-sec2+3-r1}

\title{Response to Reviewers}

\begin{document}
\maketitle



\section{Replies to the Editor}
Thank you for your careful consideration of our manuscript, and for
your useful comments. Our cover letter discusses two major changes to
the manuscript---the addition of the Hurricane Maria example and a
reorganization of background material. Here we will respond to
specific comments in your letter and in the three anonymous reviews.

\begin{quote}
\dots This can be accomplished by better sign posting of what
is background and what is a specific development of your
method.
\dots More generally, your actual contributions
are not clear described. For example, it is not clear if use of the
residuals for RDD is an innovation of this paper or a method being
taken from the literature.
\end{quote}
We have clarified the distinction between background and novel
material by restricting Section
\ref{sec:review} to background and Section \ref{sec:theMethod} to new
developments.
Regarding residualization, we refer (in the
Introduction) to our main
methodological contribution as a ``novel identifying assumption termed
`residual ignorability.''' and generally use the term ``residual
ignorability'' to define our method.
Although we note (e.g. \S~\ref{sec:robust-analys-covar}) that
traditional methods may be expressed in terms of residuals, we hope
that these changes make clear that we take residualization to be our
main, novel, contribution.

\begin{quote}
Language and notation should use the most common forms not
uncommon ones. For example the overbar arrow \dots intersection tests \dots MM
estimation
\end{quote}
We substituted boldface for overbar arrow notation for vectors, and removed reference to
the ``intersection hypothesis'' but retained reference to the
``sequential intersection-union principal.'' We referred to MM
regression as ``robust'' regression, unless the distinction between MM
and other robust models was intrinsic to our point. Following a
similar comment from reviewer 3, we refer to the outer boundary of our
window of analysis as a ``bandwidth'' and the conventional RDD
estimand as the ``LATE.''

% \begin{quote}
% I found the formal development of randomization based inference in
% Section 2 useful but the distinction of the purely background material
% from the development that was specific importance for your innovations
% was not sufficiently clear.
% \end{quote}
% We moved our discussion of Fisherian randomization based inference to
% Section \ref{sec:using-eqref-test}, and re-worded around our
% analysis of Hurricane Maria death tolls. We hope this clarifies its
% connection with our method. We removed the discussion of Neyman-style
% inference which was less directly connected to our method.

\begin{quote}
Section 2.3 is confusing. The importance of leverage and contamination
are not made clear. \dots The use of the window to motivate
the contamination and the need for robust regression needs clarity.
\end{quote}
We re-wrote our description of sample contamination (now in
\S~\ref{sec:robustFitters}) to clarify the problem, and its connection
to bandwidth selection.
We also modified our discussion of non-robust non-linear modeling
(\S~\ref{sec:nonlinear}) to clarify the issue of leverage.


\begin{quote}
There should also be a clearer explanation of the role of a window in
limitless RDD. In the introduction the expectation in the definition
is not limited to a window.
\end{quote}
We clarified the role of the window in
\S~\ref{sec:bandwidth} and \S~\ref{sec:bandwidthChoice}. In the
introduction we write ``The residual ignorability assumption and corresponding ATE
estimates pertain to all subjects in the window of analysis.'' linking
residual ignorability with a window from the outset.

\begin{quote}
The first paragraph of section 3 is superfluous and such superfluous
material can district or worse confuse readers. \dots
I would also be useful if there
was some explanation of the point of Section 3.1 before the section or
after it.
\end{quote}
We replaced the paragraph in question with one that explains the
purpose of each subsection of section 3.

\begin{quote}
On p. 13 line 49 \dots The entropy in R will not be obvious to readers and they
will need to figure out what you mean.
\end{quote}
We simplified the sentence and replaced ``entropy'' with
``randomness.''

\begin{quote}
Pp 14--15, setting alpha to 0.15 to compensate for the conservatism in
the Bonferroni correct seems odd. You will reject less but you lost
the control of familywise error at the originally desired
level. Wouldn't a less conservative method with the desired alpha
level be better?
\end{quote}
Setting alpha to a higher level will increase the power of the
specification tests to detect violations of the assumptions. We've
re-worded in \S~\ref{sec:bandwidthChoice}.
We also added citations to more powerful multiplicity adjustments in
\S~\ref{sec:balanceTesting}; however, we kept the Bonferroni procedure
in our analysis for the sake of simplicity.

\begin{quote}
In Figure 1, a vertical line at zero might be helpful.
\end{quote}
The line has been added.

\begin{quote}
In Section 5.1, it would be helpful if you explicitly defined $Y_T$.
\end{quote}
The new Section \ref{sec:levelPower} implements this suggestion.

\begin{quote}
In Table 3 the values appear to be percentages not proportion. However,
in Table 4 you present levels as proportions.
\end{quote}
In the new manuscript, we present bias, confidence interval coverage
and width, and root mean squared error. We express confidence interval
coverage as a percentage, and note it as such.

\begin{quote}
In Section 5.2 all the
generating functions are locally linear. With the appropriate window
local linear is exactly correct. Limitless is not. As generating
function with curvature might be an interesting alternative.
\end{quote}
We replaced the ``one-side'' data generating function with a
sinusoidal function, for which all the methods rely on misspecified
models.

\begin{quote}
In your inference, the fact that the same data are used to select W
and test the RDD is not considered and doesn't seem to matter in the
simulation. Can you provide some insight for this or a reference that
discusses this?
\end{quote}
We pointed out in \S~\ref{sec:bandwidthChoice} that the specification
checks use only $R$, $Z$, and covariates, but not $Y$, and give
references that that protects outcome inference.

\begin{quote}
In the Discussion the reference to random number generation is again a
distraction and should be removed.
\end{quote}
We have removed the reference.


\section{Replies to Reviewer 1}
Thank you for your valuable suggestions, which, we feel, have made the
paper stronger and more accessible. Following your input, and that of
the other reviewers, we reorganized and rewrote large parts of the
manuscript, and enlisted the services of a professional editor to help
improve the writing. We especially appreciate your suggestion to
better situate our method in the context of the ``continuity-based''
and ``local-randomization-based'' frameworks of Cattaneo et
al. (2018) and other relevant causal inference literature.

We also added a data example to help clarify our ideas. In that
example, our analysis was inspired by your suggestion that we use the
``rebar'' method of Sales et al. (2018).



\subsection{Major Comments}
\begin{quote}
In their “practical introduction to regression discontinuity designs,”
Cattaneo et al. (2018, Cambridge University Press) compare the
strength of the assumptions in the continuity- and local
randomization-based frameworks for regression discontinuity
designs. They state that the assumptions required in the local randomization framework are stronger than in the continuity one. Please
comment on this. Please also compare the strength of your assumptions
to the ones of the two other frameworks.
\end{quote}

Thank you for this valuable pointer. In a sense, the method we are
presenting falls neatly between those two frameworks.
This is explicit in the revised discussion section, which points out
that both the classical \textsc{ancova} estimator for RDDs and the
local-randomization estimator are special cases of our approach.

\begin{quote}
Please articulate how your approach is different to the approach by
Cattaneo et al. (2014, Journal of Causal Inference).
\end{quote}
Like Cattaneo et al. (2014), our method takes an explicitly
randomization-based approach to RDDs, comparing outcomes on either
side of the cutoff. Unlike Cattaneo et al., our approach allows
analysts to model a relationship between the running variable and the
outcome, so that it becomes unnecessary to assume that there is no
relationship in the window of analysis. A more detailed comparison
between the two methods can be found in \S~\ref{sec:simil-diff-with}.

\begin{quote}
Like in every approach to regression discontinuity designs, the
selection of the window seems to be central in your approach. In the
simulations, can you explore the selection of the window?
\end{quote}
We agree that this is a crucial question. However, simulating bandwidth
selection would be a complicated endeavor. Since our approach relies on
covariate balance, we would need to simulate covariates, which in turn
would require choices for functional form as well as relationships
between the simulated covariates and outcomes. The result of the
simulation study would likely depend heavily on all of those factors, so a
convincing study would require well-motivated range of parameter
choices. Based on these considerations, we decided to devote future
work to exploring covariate-based bandwidth selection, rather than
attempting it in the current paper.

\begin{quote}
Please work on the writing of sections 5 and 6.
\end{quote}
Thanks for this feedback. Both sections are substantially
revised in this version of the paper.

\subsection{Minor Comments}
\begin{itemize}
\item ``In 3.1, the notation $\dt[\thetaInf]{Y_{C}}{ R }$ is unclear.''
\begin{itemize}
  \item The text introducing $\thetaInf$ has been revised for clarity.
\end{itemize}
\item ``In (4), don’t you need something similar for $R\ge 0$?''
\begin{itemize}
 \item Thank you for this comment---you are correct. We fixed the
   statement in the revision.
 \end{itemize}
\item ``Parametric models are mentioned here and there in the
  manuscript, but can the residuals be obtained by means of
  nonparametric models in connection to Rosenbaum (2002, Statistical
  Science) where the model is just a `fit'?''
\begin{itemize}
 \item Unlike the covariance adjustment models in Rosenbaum (2002), our parametric models play an
   essential role in causal identification, rather than just reduce
   noise. Further, while in Rosenbaum (2002) $Z$ is independent of
   covariates, in our case $Z$ and $R$ are dependent. Therefore,
   residualizing $Y_C$ with a model fit to $\{Y_C,R\}$
   can \emph{induce} a dependence between residuals and $Z$, which, in turn, leads to
   bias in treatment effect estimates. For that reason, our inference
   depends on asymptotics (i.e. $\dt[\thetaInf]{Y_C}{R}$) rather than
   permutation tests. That said, our results regarding higher-order
   polynomials (\S~\ref{sec:polynomialSimulation}) suggests that there may be a role for nonparametric
   regression modeling.
\end{itemize}
\item ``For estimation, would it make sense to use matching as in Keele
  et al. (2015, Journal of the Royal Statistical Society: Series A)
  and the `rebar' method by Sales et al. (2018, Journal of Educational
  and Behavioral Statistics)?''
 \begin{itemize}
   \item Thank you for this intriguing suggestion. After careful
     consideration, we decided that to develop a connection with
     matching would be beyond the scope of this paper.  However,
     consideration of your idea led us to implement
     something along these lines (but without matching) in the new 
     Section~\ref{sec:maria}.
  \end{itemize}
\item ``Please extend on the choice of $\alpha_B=0.15$.''
\begin{itemize}
 \item We clarified the choice for $\alpha_B$ in
   \S~\ref{sec:bandwidthChoice} as a
   conservative choice---choosing a level $\alpha_B$ higher than 0.05
   leads to more rejection in specification checks, and hence stricter
   bounds on possible specifications.
\end{itemize}
\item ``In the final discussion, there seems to be something missing in
  the following sentence: `Our analysis effects adjustment for R using
  bounded influence MM- estimation.'''
\begin{itemize}
\item This sentence has been removed in the revision.
\end{itemize}
\item ``Please clarify the passage on the contamination fraction being of
order $n^{-1/2}$''
\begin{itemize}
 \item Our clarification of this concept is in the new Section \ref{sec:robustFitters};
   the ``contamination fraction'' refers to the fraction of
   observations in $\mathcal{W}$ that don't satisfy Residual
   Ignorability
\end{itemize}
\end{itemize}

\section{Reply to Reviewer 2}

Thank you for your kind review. We took up your suggesting of
including treatment effect heterogeneity into a simulation study,
and describe the result in Table 3. We agree that this is an important
issue, and plan to delve more deeply into it in future work.



\section{Replies to Reviewer 3}
Thank you for your valuable comments, which, along with those of the
other reviewers, have strengthened the paper considerably. Your
overall critique that ``the current structure of the manuscript
and writing style \dots are a poor fit for general JEBS readers'' was
shared by other reviewers as well, and upon reflection we agreed.

In response, we added an example data
analysis that we think will help illustrate our central points. We
also considerably revised the structure and writing style of the paper
to improve the logical flow and accessibility. Finally, we enlisted
the help of a professional academic editor to improve the writing. In
our revisions, we added ``guiding sentences'' and other structure to
better ``connect the ideas closely toward the newly proposed method,''
and removed ``background information that was not pertinent'' to our
argument, as your review suggested.

Finally, we are happy that you asked to see code! In fact, we had been
planning on sharing our Github repository with replication code, but
neglected to mention that in our manuscript; that omission has been
fixed. We heartily agree that code sharing should be more widespread.

\subsection{Specific Comments}
\subsubsection{Writing Style and Terminology}
\begin{quote}
[T]he authors did not explain how [the] limit concept [of Imbens and
Lemieux (2008)] is differently (or in the same manner) defined or
interpreted from what many people usually named as local average
treatment effect (LATE).
\end{quote}
The concept we were referring to is indeed the ``LATE.'' We have made
that clear (see the 3rd paragraph of Section \ref{sec:introduction}), and now refer to the
LATE estimand throughout the paper.

\begin{quote}
On page 3, the authors stated “Either circumstance calls into question
the appropriateness of limit-based methods” but did not explain why it
is so.
\end{quote}
In the fourth paragraph of the new manuscript, we added brief
explanations of the problems discrete running variables and donut
designs cause to the LATE approach.




\begin{quote}
The authors often choose terms that are less common in the education
literature when a more appropriate term exists. For example, they use
“window” instead of “bandwidth,” \dots, “local average treatment
effect”,\dots, “level” instead of “Type I error
rate,” and the format of the number themselves, in Table 3.
\end{quote}
Thank you for these pointers. In our revision, we used the common term
wherever possible. You'll notice, however, that we retain the term
``window,'' alongside ``bandwidth,'' since the concept of a bandwidth
typically refers to the exclusion of data points far from the cutoff,
while we also exclude some data \emph{at} the cutoff, as in a donut
design.

\begin{quote}
Last but not least, the article does not follow APA formatting at
all.
\end{quote}
We, in consultation with the editor we hired, revised the manuscript
to follow APA formatting by reformatting tables, captions, and
citations, and added the serial (``Oxford'') comma where appropriate.

\subsubsection{Discrete Running Variables}
\begin{quote}
[I]t seems that concern about discrete variable measured in 1/100s of a
grade is a bit overly exaggerated concern. In social science, many
scales that have more than seven levels are often considered as
continuous variables in analysis and considering the second decimal
points actually allows pretty much continuous variable. If we follow
this standard that authors pointed out, all of latent scores that even
use the item response pattern should be considered as discrete. In
addition, providing more information on how much (proportion) of the
data were actually contaminated by social corruption would make the
argument mode valid. \dots The authors fail to reference Dong (2015) which provides a correction
for running variables that are discretized due to rounding or heaping
(such as in their motivating example).
\end{quote}

This is an interesting point, and we really appreciate your pointer to
Dong (2015). As we see it, using continuous models to analyze discrete
data potentially poses two types of problems. First, the model
misspecification may cause bias, inconsistency, or some other form of
systematic error. That is the central concern of Dong (2015), as we
understand it---bias due to rounding in the running variable. In these
cases, the degree of discreteness is a crucial factor. This does not
appear to be a substantial problem in the academic probation
example---notably, our method and the conventional local-OLS method
give very similar results.

The second potential problem is that the estimand itself may be
undefined, rendering questions of bias and consistency moot. When the running variable is
rounded, the limits in the LATE refer to an underlying, unobserved
continuous running variable (denoted $X^*$ in Dong, 2015). $X^*$
could, in theory, be arbitrarily close to the RDD cutoff. In our
example, GPA is defined as discrete, so the limits that define the
LATE do not exist. We explained this distinction briefly in footnote
1, in the introduction section, where we also included citations to
Dong (2015) and another paper addressing discrete running variables.

Finally, we agree that an estimate of the amount of social
corruption/sorting around the cutoff would be interesting and add
weight to our argument. Unfortunately, we are unaware of a method for
estimating that proportion. As we note in \S~\ref{sec:choosing-mathcalw-f}, removing
students with GPAs equal to the cutoff seems to resolve much of the
problem.



\subsubsection{ Simulation Studies}

\begin{quote}
I also appreciate the motivate example but was also not sure how these
contaminated data and discrete assignment variable issues are actually
related to the presented simulation conditions or authors even tries
this or not. \dots Most importantly, there was no justification for the considered
conditions (e.g., sample size, effect size). These studies do not
provide sufficient information about the quality of the treatment
effect estimates themselves.
\end{quote}

The goal of our simulation studies was to illustrate some of the
advantages of our method, and to explore its operating characteristics
compared to other methods. Since our estimates roughly agreed with
those from the local-OLS approach, we saw little need to use
simulations to adjudicate between them. That said, we acknowledge the
need for more motivation for the simulation parameters. In our revised
manuscript, the slope and error variance were chosen based on
estimated parameters from the academic probation study.

\begin{quote}
The article would benefit from focusing more on the treatment effect
estimates by providing results in the form of treatment estimate bias,
95\% interval coverage, and quality of standard error estimates.
\end{quote}
We now report bias, and 95\% CI coverage and width in Table \ref{tab:level}, and
bias and RMSE in Table \ref{tab:poly}.

\begin{quote}
Furthermore, more conditions should be included in the simulations. In
practice, standard RD studies will often report sensitivity analysis
in which the RD analysis is done using different size bandwidths, or
windows. As one of the benefits of the proposed method is the greater
power and larger sample size, the “limitless” method should be
compared to standard RD using several different bandwidths, or
windows.
\end{quote}

We agree that these are interesting and important questions to explore
in simulation studies. However, we believe that they would be better
addressed in future work. Since our bandwidth selection technique depends on
covariate balance, a simulation study would require simulating
covariates as well as running variables and outcomes. Describing and
justifying the required simulation design choices would
add considerable length and complexity to the manuscript.
Instead, we hope to address these questions in future work.



\end{document}